{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs the following tasks:\n",
    "\n",
    "5.1 [Classify same-day permits](#5.1)\n",
    "\n",
    "\n",
    "5.2 [Regress non-same-day permits](#5.2)\n",
    "\n",
    "Kush did tasks 5.1-5.2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data tools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML tools\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data_train_clean1.csv')\n",
    "test = pd.read_csv('data_test_clean1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Classify same-day permits\n",
    "<a id='5.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(data):\n",
    "    permit_type = np.array(pd.get_dummies(data['Permit Type']))\n",
    "    existing_constrxn = np.array(pd.get_dummies(train['Existing Construction Type']))\n",
    "    proposed_constrxn = np.array(pd.get_dummies(train['Proposed Construction Type']))\n",
    "    existing_use = np.array(pd.get_dummies(train['Existing Use']))\n",
    "    proposed_use = np.array(pd.get_dummies(train['Proposed Use']))\n",
    "    plansets = np.array(pd.get_dummies(train['Plansets']))\n",
    "\n",
    "    existing_units = np.array(train['Existing Units'])\n",
    "    proposed_units = np.array(train['Proposed Units'])\n",
    "    fire_only = np.array(train['Fire Only Permit'])\n",
    "    est_cost = np.array(train['Estimated Cost'])\n",
    "    retrofit = np.array(train['Voluntary Soft-Story Retrofit'])\n",
    "\n",
    "    X = np.column_stack((permit_type,\n",
    "                         existing_constrxn, proposed_constrxn,\n",
    "                         existing_use, proposed_use,\n",
    "                         plansets,\n",
    "                         existing_units, proposed_units,\n",
    "                         fire_only, est_cost, retrofit))\n",
    "    \n",
    "    print(f\"Features have shape {X.shape}\")\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = features(train)\n",
    "X_te = features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"X_tr.csv\", X_tr, delimiter=\",\")\n",
    "np.savetxt(\"X_te.csv\", X_te, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputed data in notebook \"5 - GLRM\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_hat = np.loadtxt(\"X_tr_hat.csv\", delimiter=\",\") # GLRM-imputed data\n",
    "X_te_hat = np.loadtxt(\"X_te_hat.csv\", delimiter=\",\") # GLRM-imputed data from training set's W matrix\n",
    "\n",
    "y_tr = train['Days to issue']\n",
    "y_te = test['Days to issue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_unissued(X, y):\n",
    "    issued_permits = np.array([i for i,unissued in enumerate(y.isna()) if not unissued])\n",
    "    X = X[issued_permits,:]\n",
    "    y = y[issued_permits]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_hat, y_tr = filter_unissued(X_tr_hat, y_tr)\n",
    "X_te_hat, y_te = filter_unissued(X_te_hat, y_te)\n",
    "\n",
    "print(X_tr_hat.shape)\n",
    "print(y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_label(y):\n",
    "    baseline = sum(y == 0)/len(y)\n",
    "    print(f\"Baseline accuracy = {baseline}\")\n",
    "    \n",
    "    y_bin = y.copy()\n",
    "    y_bin[y_bin > 0] = 1\n",
    "    return y_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_bin = binarize_label(y_tr)\n",
    "y_te_bin = binarize_label(y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini test before running on full training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 30000\n",
    "rand_permits = np.random.randint(0, len(y_tr)+1, n_sample)\n",
    "X_sample = X_tr_hat[rand_permits,:]\n",
    "y_sample = y_tr_bin[rand_permits,:]\n",
    "\n",
    "X_sample_tr, X_sample_te, y_sample_tr, y_sample_te = train_test_split(X_sample, y_sample, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(X_tr, X_te, y_tr, y_te):\n",
    "    clf = SVC(C=1.0, gamma='auto')\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    \n",
    "    train_acc = clf.score(X_tr, y_tr) \n",
    "    test_acc  = clf.score(X_te, y_te)\n",
    "    print(f\"Training accuracy = {train_acc}\")\n",
    "    print(f\"Test accuracy     = {test_acc}\")\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sample = svm(X_sample_tr, X_sample_te, y_sample_tr, y_sample_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm(X_tr_hat, X_te_hat, y_tr_bin, y_te_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 Regress non-same-day permits\n",
    "<a id='5.2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sameday(X, y):\n",
    "    sameday_bools = (y == 0)\n",
    "    # nsps = non-same-day permits\n",
    "    nsps = np.array([i for i,sameday in enumerate(sameday_bools) if not sameday])\n",
    "    X = X[nsps,:]\n",
    "    y = y[nsps]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_hat_nsp, y_tr_nsp = filter_sameday(X_tr_hat, y_tr)\n",
    "X_te_hat_nsp, y_te_nsp = filter_sameday(X_te_hat, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_tr_nsp)\n",
    "plt.xlabel(\"Days to issue non-same-day permits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=5)\n",
    "regr.fit(X_tr_hat_nsp, y_tr_nsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_acc(X, y):\n",
    "    R_sq = regr.score(X, y)\n",
    "    pred = np.maximum(regr.predict(X_tr), 1)\n",
    "    MSE = np.mean((pred-y)**2)\n",
    "    RMSE = MSE**0.5\n",
    "    \n",
    "    print(f\"R^2  = {R_sq}\")\n",
    "    print(f\"RMSE = {RMSE}\")\n",
    "\n",
    "    # where is underfitting?\n",
    "    plt.scatter(pred, y)\n",
    "    plt.xlabel(\"Prediction\")\n",
    "    plt.ylabel(\"Observation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_acc(X_tr_hat_nsp, y_tr_nsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_acc(X_te_hat_nsp, y_te_nsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we determine if the complicated stuff above (added features, GLRM, same-day classifier, RandomForest regressor) was worth the effort:\n",
    "\n",
    "1. Did it improve on the linear regression? \n",
    "\n",
    "2. Is it deployable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to be fancier, we could use a zero-inflation GLM with a negative-binomial distribution, since the response is overdispersed:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean days to issue     = {np.mean(y_tr_nsp)}\")\n",
    "print(f\"Variance days to issue = {np.var(y_tr_nsp)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
